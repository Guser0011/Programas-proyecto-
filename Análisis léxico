using System;
using System.Collections.Generic;
using System.Text.RegularExpressions;

public enum TokenType
{
    Keyword, Identifier, Number, String, Operator, Delimiter, Unknown
}

public class Token
{
    public TokenType Type { get; }
    public string Value { get; }

    public Token(TokenType type, string value)
    {
        Type = type;
        Value = value;
    }

    public override string ToString() => $"{Type}: {Value}";
}

public class Lexer
{
    private readonly string _input;
    private readonly List<Token> _tokens;

    public Lexer(string input)
    {
        _input = input;
        _tokens = new List<Token>();
    }

    public List<Token> Tokenize()
    {
        var patterns = new Dictionary<TokenType, string>
        {
            { TokenType.Keyword, @"\b(BEGIN|END|CHARACTER|AT|EVENT|IF|THEN|ELSE|ENDIF|PRINT|STOP|VAR)\b" },
            { TokenType.Identifier, @"[a-zA-Z_][a-zA-Z0-9_]*" },
            { TokenType.Number, @"\b\d+\b" },
            { TokenType.String, @"""([^""]*)""" },
            { TokenType.Operator, @"(==|>=|<=|>|<|\+|\-|\*|\/)" },
            { TokenType.Delimiter, @"[();,=]" }
        };

        var regex = new Regex(string.Join("|", patterns.Select(p => $"(?<{p.Key}>{p.Value})")));
        var matches = regex.Matches(_input);

        foreach (Match match in matches)
        {
            foreach (var type in patterns.Keys)
            {
                if (match.Groups[type.ToString()].Success)
                {
                    _tokens.Add(new Token(type, match.Value));
                    break;
                }
            }
        }

        return _tokens;
    }
}
